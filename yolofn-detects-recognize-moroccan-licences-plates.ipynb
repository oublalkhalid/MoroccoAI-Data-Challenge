{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# License Plate Detection on Moroccan Cars using YOLOv3 with Flow Normalizing (YoloFN v3)\n\n![https://raw.githubusercontent.com/oublalkhalid/MoroccoAI-Data-Challenge/main/images/workflow.png](https://raw.githubusercontent.com/oublalkhalid/MoroccoAI-Data-Challenge/main/images/workflow.png)\nThis repository guides you through the steps for annotating and training a custom model to detect and blur the license plates on Morrocan licence plates.[Please consult our Pipline and the associated paper in the repository. ](http://github.com/oublalkhalid/MoroccoAI-Data-Challenge)\nWe also mention that more than 3go of data are generated to increase the training data of our Yolo (We also have the weight of yolo tiyni which gives a score of 0.59 on the dataset of this challenge).\n\n> Please follow the associated article for more details - (Please check our paper after submission deadline).\n\n","metadata":{"id":"7HAaavQRKBMy"}},{"cell_type":"markdown","source":"# Step 1: Prepare the dataset\n\nWe get from Morroco-IA more than 18900 images of Morrocain licences with the number plate. \n\n1. To strat we create 2 folders 'test' and 'train' and transfer 20% of the images in test and 80% images in train folders respectively.\n\n2. Alternatively, you can use the test and train data used by me for training. Download test.zip and train.zip files from our Github Repository for accessing the annotated images.\n\n3. Annotate the license plates in all the images in the respective test and train folders, using LabelImg, and generate the annotated .xml file for the images within the respective folders. You can get more details on LabelImg from [here\n](https://github.com/tzutalin/labelImg).(Conversion process is mentioned in step 3)\n","metadata":{"id":"Yp7X-4vW6OpZ"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\npath=\"/kaggle/input\"\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-20T23:06:02.060617Z","iopub.execute_input":"2021-12-20T23:06:02.060997Z","iopub.status.idle":"2021-12-20T23:06:02.273196Z","shell.execute_reply.started":"2021-12-20T23:06:02.060964Z","shell.execute_reply":"2021-12-20T23:06:02.269215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Installing the base darknet system","metadata":{"id":"e5_UIvTs7OvH"}},{"cell_type":"code","source":"# Download YOLOv3 project\n! git clone https://github.com/AlexeyAB/darknet","metadata":{"id":"U6nAqAPL9MgR","execution":{"iopub.status.busy":"2021-12-20T23:06:12.272537Z","iopub.execute_input":"2021-12-20T23:06:12.272807Z","iopub.status.idle":"2021-12-20T23:06:15.019422Z","shell.execute_reply.started":"2021-12-20T23:06:12.272776Z","shell.execute_reply":"2021-12-20T23:06:15.018424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install the base darknet framework\n%cd darknet\n! make","metadata":{"id":"ZTscV_6P8ToS","execution":{"iopub.status.busy":"2021-12-20T23:06:19.253028Z","iopub.execute_input":"2021-12-20T23:06:19.253341Z","iopub.status.idle":"2021-12-20T23:06:47.974081Z","shell.execute_reply.started":"2021-12-20T23:06:19.253304Z","shell.execute_reply":"2021-12-20T23:06:47.973181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uplod test and train directories in the darknet directory along with the convert.py file from this respository and run the below command\n# This step will pick the coordinates from each .xml file and put them into YOLO compatible .txt file in the same test and train directories.\n # Also, train.txt and test.txt files are created within the darknet folder, containing the location of images.\n\n#python convert.py\nimport glob\nimport os\nimport pickle\nimport xml.etree.ElementTree as ET\nfrom os import listdir, getcwd\nfrom os.path import join\n\n\ndef get_images_in_dir(dir_path):\n    image_list = []\n    for filename in glob.glob(dir_path + '/*.jpg'):\n        image_list.append(filename)\n\n    return image_list\n\n\ndef convert(size, box):\n    dw = 1./(size[0])\n    dh = 1./(size[1])\n    x = (box[0] + box[1])/2.0 - 1\n    y = (box[2] + box[3])/2.0 - 1\n    w = box[1] - box[0]\n    h = box[3] - box[2]\n    x = x*dw\n    w = w*dw\n    y = y*dh\n    h = h*dh\n    return (x,y,w,h)\n\n\ndef convert_annotation(dir_path, output_path, image_path):\n    basename = os.path.basename(image_path)\n    basename_no_ext = os.path.splitext(basename)[0]\n\n    in_file = open(dir_path + '/' + basename_no_ext + '.xml')\n    out_file = open(output_path + basename_no_ext + '.txt', 'w')\n    tree = ET.parse(in_file)\n    root = tree.getroot()\n    size = root.find('size')\n    w = int(size.find('width').text)\n    h = int(size.find('height').text)\n\n    for obj in root.iter('object'):\n        difficult = obj.find('difficult').text\n        cls = obj.find('name').text\n        if cls not in classes or int(difficult)==1:\n            continue\n        cls_id = classes.index(cls)\n        xmlbox = obj.find('bndbox')\n        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n        bb = convert((w,h), b)\n        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n\n\ncwd = getcwd()\ndirs = ['train','test']\nclasses = ['LP']\n\nfor dir_path in dirs:\n    full_dir_path = cwd + '/' + dir_path\n    output_path = full_dir_path + '/'\n\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    image_paths = get_images_in_dir(full_dir_path)\n    list_file = open(full_dir_path + '.txt', 'w')\n\n    for image_path in image_paths:        \n        list_file.write(image_path + '\\n')\n        convert_annotation(full_dir_path, output_path, image_path)\n    list_file.close()\n\n    print(\"Finished processing: \" + dir_path)","metadata":{"id":"s0evHLMDB44Z","execution":{"iopub.status.busy":"2021-12-20T23:25:30.750206Z","iopub.execute_input":"2021-12-20T23:25:30.75053Z","iopub.status.idle":"2021-12-20T23:25:30.77201Z","shell.execute_reply.started":"2021-12-20T23:25:30.750495Z","shell.execute_reply":"2021-12-20T23:25:30.771251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis Input Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport sys\nimport matplotlib.pyplot as plt\nfrom tqdm import trange \nimport pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\ntrain_string=pd.read_csv(path+'/moroccoai-data-challenge-edition-001/train.csv')\ntrain_string[\"class\"]=train_string[\"plate_string\"]\ntrain_string.astype(str)\ntrain_string.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T23:45:04.91154Z","iopub.execute_input":"2021-12-20T23:45:04.911823Z","iopub.status.idle":"2021-12-20T23:45:04.953505Z","shell.execute_reply.started":"2021-12-20T23:45:04.911776Z","shell.execute_reply":"2021-12-20T23:45:04.952612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in trange((train_string.shape[0])):\n    if \"b\" in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"b\"\n    elif \"j\" in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"j\"\n    elif \"ch\" in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"ch\"\n    elif \"ww\" in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"w\"\n    elif \"m\" in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"m\"\n    elif \"a\" in train_string[\"plate_string\"][k] and \"waw\" not in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"a\"\n    elif \"d\" in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"d\"\n    elif \"h\" in train_string[\"plate_string\"][k] and \"ch\" not in train_string[\"plate_string\"][k] :\n        train_string[\"class\"][k]=\"h\"\n    elif \"waw\" in train_string[\"plate_string\"][k]:\n        train_string[\"class\"][k]=\"ch\"\n    else: \n        train_string[\"class\"][k]=\"other\"\ntrain_string.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T23:45:09.102804Z","iopub.execute_input":"2021-12-20T23:45:09.103202Z","iopub.status.idle":"2021-12-20T23:45:09.293654Z","shell.execute_reply.started":"2021-12-20T23:45:09.103167Z","shell.execute_reply":"2021-12-20T23:45:09.29298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We have Unbalanced case on the training Dataset --> Log Transformation","metadata":{}},{"cell_type":"code","source":"train_string.groupby(['class']).sum().unstack().plot(kind='bar',color='green')\nplt.xlabel(\"Class\")\nplt.ylabel(\"Count\")","metadata":{"execution":{"iopub.status.busy":"2021-12-20T23:45:34.090073Z","iopub.execute_input":"2021-12-20T23:45:34.090337Z","iopub.status.idle":"2021-12-20T23:45:34.301201Z","shell.execute_reply.started":"2021-12-20T23:45:34.0903Z","shell.execute_reply":"2021-12-20T23:45:34.300559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Prepare custom 'my_data' folder","metadata":{"id":"bysCNUhpC0eF"}},{"cell_type":"code","source":"# Run the below command to make a custom folder named 'my_data'\n! mkdir my_data","metadata":{"id":"YA_zSaIFCEBk","execution":{"iopub.status.busy":"2021-12-20T16:23:54.028695Z","iopub.execute_input":"2021-12-20T16:23:54.029356Z","iopub.status.idle":"2021-12-20T16:23:54.693323Z","shell.execute_reply.started":"2021-12-20T16:23:54.029321Z","shell.execute_reply":"2021-12-20T16:23:54.692394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the train.txt and test.txt files from the darknet directory to the my_data directory.\n! mv train.txt my_data/ \n! mv test.txt my_data/","metadata":{"id":"d8CBMydTC6N2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create classes.names file within my_data directory with class name as \"LP\"\n! touch /content/gdrive/MyDrive/darknet/my_data/classes.names \n! echo LP > /content/gdrive/MyDrive/darknet/my_data/classes.names","metadata":{"id":"XjoLs0cKDJkp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create weights directory within the my_data directory\n! mkdir my_data/weights","metadata":{"id":"jOu0cR-DDQVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create file darknet.data within my_data directory to provide the configuration details\n! touch /content/gdrive/MyDrive/darknet/my_data/darknet.data\n\n# Paste the below details manually in darknet.data file\n## classes = 1\n## train = my_data/train.txt\n## valid = my_data/test.txt\n## names = my_data/classes.names\n## backup = my_data/weights/","metadata":{"id":"pbRVcxVlEJ8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy and Paste the cfg file from darknet/cfg/yolov3.cfg to darknet/my_data directory\n! cp /content/gdrive/MyDrive/darknet/cfg/yolov3.cfg /content/gdrive/MyDrive/darknet/my_data\n\n# Make the following changes in yolov3.cfg in my_data directory.\n# Line 603, 693, and 780 change the filters to 18. (filters = (classes + 5) * 3). \n#In our case we are detecting only 1 class, so the number of filters will be equal to 18.\n# Line 783, change the number of classes to 1.","metadata":{"id":"DtzTT1aIG26H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 5: Download the initial yolo weights for training the custom data**","metadata":{"id":"RaVsTPPkIVro"}},{"cell_type":"code","source":"# Run the following command from the darknet directory\n! wget https://pjreddie.com/media/files/darknet53.conv.74","metadata":{"id":"K-xYWSasIW5C","execution":{"iopub.status.busy":"2021-12-20T16:24:10.027714Z","iopub.execute_input":"2021-12-20T16:24:10.028462Z","iopub.status.idle":"2021-12-20T16:24:18.90233Z","shell.execute_reply.started":"2021-12-20T16:24:10.028422Z","shell.execute_reply":"2021-12-20T16:24:18.901457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6: Set criteria to save the weights file in the weights **directory**","metadata":{"id":"EBf9BkL2IneA"}},{"cell_type":"code","source":"# Open detector.c file from darknet/examples directory and change line number 138 as shown below.\n\nif(i%1000==0 or (i < 1000 and i%200 == 0)):\n\n# This change saves the weight in my_data/weights directory for every 200th iteration till 1000 iterations and then for every 1000th iteration.","metadata":{"id":"hLg01QFuIoss","execution":{"iopub.status.busy":"2021-12-20T16:25:28.972992Z","iopub.execute_input":"2021-12-20T16:25:28.973532Z","iopub.status.idle":"2021-12-20T16:25:28.978396Z","shell.execute_reply.started":"2021-12-20T16:25:28.973496Z","shell.execute_reply":"2021-12-20T16:25:28.977323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 7: Now start the **training**","metadata":{"id":"HBYdMlf-I4v-"}},{"cell_type":"code","source":"# Run the following command from the darknet directory\n! ./darknet detector train /content/gdrive/MyDrive/darknet/my_data/darknet.data /content/gdrive/MyDrive/darknet/my_data/yolov3.cfg /content/gdrive/MyDrive/darknet/darknet53.conv.74","metadata":{"id":"_pT7qzmCI5pa","execution":{"iopub.status.busy":"2021-12-20T16:25:35.329912Z","iopub.execute_input":"2021-12-20T16:25:35.330442Z","iopub.status.idle":"2021-12-20T16:25:36.013076Z","shell.execute_reply.started":"2021-12-20T16:25:35.330406Z","shell.execute_reply":"2021-12-20T16:25:36.01207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 8: Detect and Blur the Licence Plate from the **image**","metadata":{"id":"XmfBDJyzJkaN"}},{"cell_type":"code","source":"# Change the weightsPath in line number 12 and the image file name in line number 15 before running the below code\n\n%matplotlib inline\nimport numpy as np\nimport imutils\nimport cv2\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nCONF_THRESH, NMS_THRESH = 0.5, 0.5\n\n\nweightsPath = 'custom/weights/yolov3_8000.weights'\nconfigPath = 'custom/yolov3.cfg'\nnamesPath = 'custom/classes.names'\nimage = 'img3.jpeg'\n\n# Load the network using openCV\nnet = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\nnet.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\nnet.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n\n# Get the output layer from YOLOv3\nlayers = net.getLayerNames()\noutput_layers = [layers[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n\n\n# Read and convert the image to blob and perform forward pass\nimg = cv2.imread(image)\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nheight, width = img.shape[:2]\n\nblob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), swapRB=True, crop=False)\nnet.setInput(blob)\nlayer_outputs = net.forward(output_layers)\n\n\nclass_ids, confidences, b_boxes = [], [], []\nfor output in layer_outputs:\n    for detection in output:\n        scores = detection[5:]\n        class_id = np.argmax(scores)\n        confidence = scores[class_id]\n\n        if confidence > CONF_THRESH:\n            center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n\n            x = int(center_x - w / 2)\n            y = int(center_y - h / 2)\n\n            b_boxes.append([x, y, int(w), int(h)])\n            confidences.append(float(confidence))\n            class_ids.append(int(class_id))\n\n\n# Perform non maximum suppression for the bounding boxes to filter overlapping and low confident bounding boxes\nindices = cv2.dnn.NMSBoxes(b_boxes, confidences, CONF_THRESH, NMS_THRESH).flatten().tolist()\n\nif len(indices) > 0:\n\n    # Draw the filtered bounding boxes with their class to the image\n    with open(namesPath, \"r\") as f:\n        classes = [line.strip() for line in f.readlines()]\n    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n\n    for index in indices:\n        (x,y) = (b_boxes[index][0], b_boxes[index][1])\n        (w,h) = (b_boxes[index][2], b_boxes[index][3])\n        \n        # Blur the ROI of the detected licence plate \n        img[y:y+h, x:x+w] = cv2.GaussianBlur(img[y:y+h, x:x+w] ,(35,35),0)\n\n        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n        text = \"{}: {:.4f}\".format(\"LP\", confidences[index])\n        cv2.putText(img, text, (x, y - 3), cv2.FONT_HERSHEY_COMPLEX_SMALL, .75 , (0, 255, 0), 1)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(img)\nplt.show()","metadata":{"id":"X02AWj2CJmWo","execution":{"iopub.status.busy":"2021-12-20T16:25:41.410259Z","iopub.execute_input":"2021-12-20T16:25:41.410927Z","iopub.status.idle":"2021-12-20T16:25:41.484746Z","shell.execute_reply.started":"2021-12-20T16:25:41.410879Z","shell.execute_reply":"2021-12-20T16:25:41.482464Z"},"trusted":true},"execution_count":null,"outputs":[]}]}